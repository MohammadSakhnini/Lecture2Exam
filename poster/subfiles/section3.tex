%!TEX root = ../hbrs-poster.tex


\block{Survey}
{
%    Assign the question pools to their respective writer.

   	\begin{tcolorbox}[skin=widget,
    	coltitle=black,
    	colframe=s-group1!30,
    	colback=s-group1!10,
    	fontupper=\tiny,
    	adjusted title=Group 1,
    	boxrule=2mm]
	   	\begin{itemize}
	   		\setlength\itemsep{-0.2em}
			\item What is the importance of adding special tokens like [CLS], [PAD], [SEP], and [MASK] during the preprocessing of text data for transformer models.
			\item What is a Retrieval Augmented Generator (RAG) system, and how does it help in reducing the context size for document retrieval and generation tasks?
			\item What is the purpose of using Term Frequency â€“ Inverse Document Frequency (TFIDF)?
	 	\end{itemize}
    \end{tcolorbox}
       	
    \begin{tcolorbox}[skin=widget,
    	coltitle=black,
    	colframe=s-group2!30,
    	colback=s-group2!10,
    	fontupper=\tiny,
    	adjusted title=Group 2,
    	boxrule=2mm]
    	\begin{itemize}
	   		\setlength\itemsep{-0.2em}
    		\item Explain how one-hot encoding works and provide an example using a simple sentence.
    		\item How do transformers solve the problem of parallelization in sequence-to-sequence models and why is this significant for NLP tasks?
    		\item What is the primary purpose of training language models with human feedback?
    	\end{itemize}
    \end{tcolorbox}
   	
   	\begin{tcolorbox}[skin=widget,
    	coltitle=black,
    	colframe=s-group3!30,
    	colback=s-group3!10,
    	fontupper=\tiny,
    	adjusted title=Group 3,
    	boxrule=2mm]
    	\begin{itemize}
	   		\setlength\itemsep{-0.2em}
    		\item How does prefix tuning differ from parameter-efficient fine-tuning methods like LoRa, in terms of their approach to updating parameters while maintaining model efficiency?
			\item What is the intuition behind the smoothing techniques in statistical language modeling, and how do they help with the sparsity issue of n-gram models?
			\item What is the role of the Byte Pair Encoding (BPE) token learner algorithm in text preprocessing?

    	\end{itemize}
    \end{tcolorbox}
       	
     \begin{tcolorbox}[skin=widget,
    	coltitle=black,
    	colframe=s-group4!30,
    	colback=s-group4!10,
    	fontupper=\tiny,
    	adjusted title=Group 4,
    	boxrule=2mm]
    	\begin{itemize}
    		\setlength\itemsep{-0.2em}
    		\item What is model adaption and what is used for? Name at least 2 types of model adaption and explain them and provide an example for each of them.
    		\item What does a positional encoder in the Transformer Encoder do? How does it effect the self-attention mechanism?
    		\item How does TF-IDF differ from One Hot Encoding? What are the advantages of TF-IDF over One Hot Encoding?

    	\end{itemize}
    \end{tcolorbox}
    
}

