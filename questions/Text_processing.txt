---------------------------------------------------------------------------------------

1) What is the role of regular expressions in text processing? Why are they necessary for NLP tasks? Provide an example of a regular expression and its corresponding matches.
2) Explain how the BPE algorithm works for tokenization, specifically focusing on merging adjacent symbols to form new tokens. Provide an example of this process with a small corpus.
3) How does the BPE algorithm handle punctuation marks, such as periods (.)? What rules are used to determine if a period signifies a sentence boundary or part of a word?
4) Discuss the importance of subword tokenization in NLP and its role in improving models' performance on tasks like language translation and text summarization. Which algorithms are commonly used for this purpose, and what are their key differences?
5) Analyze the advantages and disadvantages of using byte pair encoding (BPE) as a subword tokenization method. How does it compare to other popular methods, such as WordPiece or Unigram language modeling tokenization? Provide examples of how BPE's tokenization process might affect the performance of an NLP model on specific tasks.

    Question 5:
    
    Which algorithm among Byte-Pair Encoding (BPE), WordPiece, and Unigram language modeling tokenization is most likely to result in subword units that represent morphemes?
    
    A) Byte-Pair Encoding (BPE)
    B) WordPiece
    C) Unigram language modeling tokenization

    Answer: A) Byte-Pair Encoding (BPE)